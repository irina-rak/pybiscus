root_dir: ${oc.env:PWD}

trainer:
  max_epochs: 800
  accumulate_grad_batches: 4  # Not supported with manual optimization
  check_val_every_n_epoch: 1  # Validate every n epochs to save time
  log_every_n_steps: 10  # Log more frequently for monitoring
  hardware:
    precision: 16-mixed
    accelerator: gpu
    strategy: ddp_find_unused_parameters_true
    devices:
      - 0
      - 1
      - 2
      - 3
  metrics_loggers:
    - name: wandb
      config:
        api_key_definition:
          env_var_name: WANDB_API_KEY
        params:
          project: "Prostate_Bladder_Rectum"
          group: "pbr_gen_${model.name}"
          # name: "pbr_gen_local_INT_e${trainer.max_epochs}"
          name: "pbr_${model.name}_local_INT_URY_e${trainer.max_epochs}_roi_${data.config.patch_size[0]}_${now:%Y%m%d_%H%M}"
          
          # project: "Decathlon"
          # group: "Task01_BrainTumour"
          # name: "BT_${model.name}_local_e${trainer.max_epochs}_${now:%Y%m%d_%H%M%S}"

          job_type: "server"
          is_client: false
  reporting_path: ${root_dir}/experiments/${trainer.metrics_loggers[0].config.params.group}/${trainer.metrics_loggers[0].config.params.name}

data:
  name: pbr_gen
  config:
    dir_train: ${root_dir}/datasets/INT_URY/train_split.json
    dir_val: ${root_dir}/datasets/INT_URY/val_split.json
    dir_test: None

    # dir_train: ${root_dir}/datasets/
    # dir_val: ${root_dir}/datasets/
    # dir_test: ${root_dir}/datasets/

    task_type: "generation"  # This will use LDM preprocessing
    # patch_size: [96, 96, 96]
    # patch_size: [128, 96, 128]
    patch_size: [192, 192, 128]
    spacing: [1.0, 1.0, 2.0]
    # spacing: [2.0, 2.0, 3.0]
    margin: 10
    augment: True  # Enable augmentation for better generalization
    cache_rate: 1.0
    batch_size: 1
    num_workers: 8

# model:
#   name: klae
#   pretrained_weights_path: ${root_dir}/experiments/local/pbr_klae_local_INT_URY_e150_roi_96_20250727_2212_transfer/MultipleMetricsLogger/version_0/checkpoints/pbr_klae_local_INT_URY_e150_roi_96_20250727_2212_transfer.ckpt
#   config:
#     generator_config:
#       spatial_dims: 3
#       in_channels: 1
#       out_channels: 1
#       channels: [32, 64, 64]
#       attention_levels: [False, False, True]
#       latent_channels: 3
#       num_res_blocks: 1
#       norm_num_groups: 16
#     discriminator_config:
#       spatial_dims: 3
#       num_layers_d: 3
#       channels: 32
#       in_channels: 1
#       out_channels: 1
#       kernel_size: 4
#     lr:
#       - 1e-4
#       - 1e-4
#     perceptual_weight: 0.001
#     kl_weight: 1e-6
#     reconstruction_weight: 1.0
#     adv_weight: 0.01
#     autoencoder_warm_up_n_epochs: 15
#     seed: 4294967295

# model:
#   name: vqvae
#   pretrained_weights_path: ${root_dir}/experiments/pbr_gen_vqvae/pbr_vqvae_local_INT_URY_e100_roi_192_20250729_0008_transfer/MultipleMetricsLogger/version_0/checkpoints/pbr_vqvae_local_INT_URY_e100_roi_192_20250729_0008_transfer.ckpt
#   config:
#     vqvae_config:
#       spatial_dims: 3
#       in_channels: 1
#       out_channels: 1
#       channels: [96, 96, 192]
#       num_res_layers: 3
#       num_res_channels: [96, 96, 192]
#       # downsample_parameters:
#       #   - [2, 4, 1, 1]
#       #   - [2, 4, 1, 1]
#       #   - [2, 4, 1, 1]
#       # upsample_parameters:
#       #   - [2, 4, 1, 1, 0]
#       #   - [2, 4, 1, 1, 0]
#       #   - [2, 4, 1, 1, 0]
#       num_embeddings: 32
#       embedding_dim: 64
#       use_checkpointing: True
#     lr: 1e-4
#     seed: 4294967295

model:
  name: dunet
  # pretrained_weights_path: ${root_dir}/experiments/pbr_gen_${model.name}/pbr_dunet_local_INT_URY_e100_roi_192_20250729_1623/MultipleMetricsLogger/version_0/checkpoints/pbr_dunet_local_INT_URY_e100_roi_192_20250729_1623.ckpt
  config:
    unet_config:
      spatial_dims: 3
      in_channels: 64
      out_channels: 64
      channels: [128, 256, 256]
      attention_levels: [False, False, True]
      num_res_blocks: 1
      norm_num_groups: 32
      num_head_channels: 256

    scheduler_config:
      num_train_timesteps: 1000
      schedule: "scaled_linear_beta"
      beta_start: 0.0015
      beta_end: 0.0195

    generator_config:
      spatial_dims: 3
      in_channels: 1
      out_channels: 1
      channels: [96, 96, 192]
      num_res_layers: 3
      num_res_channels: [96, 96, 192]
      # downsample_parameters:
      #   - [2, 4, 1, 1]
      #   - [2, 4, 1, 1]
      #   - [2, 4, 1, 1]
      # upsample_parameters:
      #   - [2, 4, 1, 1, 0]
      #   - [2, 4, 1, 1, 0]
      #   - [2, 4, 1, 1, 0]
      num_embeddings: 32
      embedding_dim: 64
      # use_checkpointing: True

    # discriminator_config:
    #   spatial_dims: 3
    #   num_layers_d: 3
    #   channels: 32
    #   in_channels: 1
    #   out_channels: 1
    #   kernel_size: 4
    autoencoder_weights: ${root_dir}/experiments/pbr_gen_vqvae//pbr_vqvae_local_INT_URY_e100_roi_192_20250729_0119_transfer/MultipleMetricsLogger/version_0/checkpoints/pbr_vqvae_local_INT_URY_e100_roi_192_20250729_0119_transfer.ckpt
    lr: 1e-4
    seed: 4294967295